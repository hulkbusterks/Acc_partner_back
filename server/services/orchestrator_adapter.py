"""Simple mock-only orchestrator adapter (reverted to keep the PoC stable).

This module provides a minimal in-process orchestrator used for local testing
and development. It intentionally avoids heavy runtime dependencies.
"""
from typing import Any, Dict

from server.services.faiss_store import store as faiss_store
from server.services.evidence_check import deterministic_evidence_check
import os
from typing import Optional


class OrchestratorAdapter:
    def run_rag_pipeline(self, session_id: str, block: Dict[str, Any]) -> Dict[str, Any]:
        raise NotImplementedError()


class MockOrchestrator(OrchestratorAdapter):
    def run_rag_pipeline(self, session_id: str, block: Dict[str, Any]) -> Dict[str, Any]:
        action = block.get("action")
        if action == "propose_topics":
            candidates = block.get("candidates", [])
            topics = []
            for i, c in enumerate(candidates[:5]):
                topics.append({"title": f"Auto Topic {i+1}", "source_chunks": {"ids": [c.get("id")]}})
            return {"topics": topics}

        if action == "generate_mcqs":
            n = int(block.get("n", 3))
            out_questions = []
            for i in range(n):
                hits = faiss_store.query(block.get("seed") or "", k=3)
                source_ids = [h for h, _ in hits]
                q = {
                    "question": f"Sample MCQ {i+1}: Which option is correct?",
                    "choices": ["Alpha", "Beta", "Gamma", "Delta"],
                    "correct_index": i % 4,
                    "explanation": "Generated by mock orchestrator",
                }
                # optionally run deterministic evidence check if enabled
                verify_flag = os.getenv("ORCHESTRATOR_VERIFY", "false").lower() in ("1", "true", "yes")
                det_supported = False
                evidence = ""
                if verify_flag:
                    # gather context texts from faiss_store items
                    contexts = []
                    for sid in source_ids:
                        item = faiss_store.items.get(sid)
                        if isinstance(item, dict):
                            contexts.append(item.get("text"))
                        else:
                            contexts.append(item)
                    det_supported, evidence = deterministic_evidence_check(q, contexts)

                out_questions.append({
                    "question_id": f"mock-mcq-{i+1}",
                    "question_json": q,
                    "verified": True if not verify_flag else det_supported,
                    "deterministic_supported": det_supported,
                    "evidence": evidence or "(mock)",
                    "source_chunks": source_ids,
                })
            return {"questions": out_questions}

        return {"questions": []}


def get_orchestrator_adapter() -> OrchestratorAdapter:
    provider = os.getenv("ORCHESTRATOR", "rag").lower()
    if provider == "mock":
        return MockOrchestrator()

    if provider == "rag":
        # Direct retrieval-backed orchestrator â€” no extra config needed.
        # Uses FAISS content to build context-aware MCQs.
        from langgraph_samples.rag_graph import RetrievalBackedGraph

        class RAGOrchestrator(OrchestratorAdapter):
            def __init__(self):
                self.graph = RetrievalBackedGraph()

            def run_rag_pipeline(self, session_id: str, block: Dict[str, Any]) -> Dict[str, Any]:
                return self.graph.run(block) or {}

        return RAGOrchestrator()

    if provider in ("langgraph", "lang-graph"):
        # Lazy-load LangGraph to avoid import-time failures when not used
        lg = None
        try:
            import langgraph as lg_mod  # type: ignore
            lg = lg_mod
        except Exception:
            lg = None

        class LangGraphAdapter(OrchestratorAdapter):
            def __init__(self):
                self.graph = None
                self.graph_path = os.getenv("LANGGRAPH_GRAPH_PATH")
                if not self.graph_path:
                    raise RuntimeError("Set LANGGRAPH_GRAPH_PATH when using ORCHESTRATOR=langgraph")
                loader_errs = []

                # If langgraph module is available, prefer its loaders
                if lg is not None:
                    try:
                        if hasattr(lg, "load"):
                            self.graph = lg.load(self.graph_path)
                        elif hasattr(lg, "load_graph"):
                            self.graph = lg.load_graph(self.graph_path)
                        elif hasattr(lg, "Graph"):
                            G = getattr(lg, "Graph")
                            if hasattr(G, "load"):
                                self.graph = G.load(self.graph_path)
                            elif hasattr(G, "from_file"):
                                self.graph = G.from_file(self.graph_path)
                            else:
                                try:
                                    self.graph = G(self.graph_path)
                                except Exception as ee:
                                    loader_errs.append(str(ee))
                        else:
                            loader_errs.append("no known loader on langgraph module")
                    except Exception as ee:
                        loader_errs.append(str(ee))

                # If langgraph isn't installed or failed, allow loading a python file
                if self.graph is None:
                    try:
                        import importlib.util
                        import os as _os
                        if _os.path.isfile(self.graph_path) and self.graph_path.endswith('.py'):
                            spec = importlib.util.spec_from_file_location('lg_user_graph', self.graph_path)
                            mod = importlib.util.module_from_spec(spec)
                            spec.loader.exec_module(mod)  # type: ignore
                            # attempt same loader patterns on the user module
                            if hasattr(mod, 'load'):
                                self.graph = mod.load(self.graph_path)
                            elif hasattr(mod, 'load_graph'):
                                self.graph = mod.load_graph(self.graph_path)
                            elif hasattr(mod, 'Graph'):
                                G = getattr(mod, 'Graph')
                                if hasattr(G, 'load'):
                                    self.graph = G.load(self.graph_path)
                                elif hasattr(G, 'from_file'):
                                    self.graph = G.from_file(self.graph_path)
                                else:
                                    try:
                                        self.graph = G(self.graph_path)
                                    except Exception as ee:
                                        loader_errs.append(str(ee))
                            else:
                                # module may itself implement run/execute directly
                                self.graph = mod
                        else:
                            loader_errs.append('graph path is not a .py file or does not exist')
                    except Exception as ee:
                        loader_errs.append(str(ee))

                if self.graph is None:
                    raise RuntimeError(f"Failed to load LangGraph graph: {loader_errs}")

            def run_rag_pipeline(self, session_id: str, block: Dict[str, Any]) -> Dict[str, Any]:
                if self.graph is None:
                    raise RuntimeError("LangGraph graph not loaded")
                # Try common run interfaces
                if hasattr(self.graph, "run"):
                    return self.graph.run(block) or {}
                if hasattr(self.graph, "execute"):
                    return self.graph.execute(block) or {}
                if hasattr(self.graph, "__call__"):
                    return self.graph(block) or {}
                raise RuntimeError("LangGraph graph object has no callable interface")

        return LangGraphAdapter()

    raise RuntimeError(f"Unknown ORCHESTRATOR provider '{provider}'. Supported: 'mock' or 'langgraph'.")